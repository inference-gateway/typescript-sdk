import {
  InferenceGatewayClient,
  MessageRole,
  Provider,
} from '../../src/index.js';

/**
 * Demonstration of MCP filesystem operations with proper directory access
 * This example shows how to work with the /shared and /tmp directories
 * and demonstrates the onMCPTool callback for tracking tool usage
 */
(async () => {
  const client = new InferenceGatewayClient({
    baseURL: 'http://localhost:8080/v1',
  });

  const provider = (process.env.PROVIDER as Provider) || Provider.groq;
  const model = process.env.LLM || 'llama-3.3-70b-versatile';

  console.log(`Using model: ${model}`);
  console.log(`Using provider: ${provider}\n`);

  console.log('=== MCP Tool Usage Demo ===\n');

  try {
    // Check gateway health
    console.log('üîç Checking gateway health...');
    const isHealthy = await client.healthCheck();
    console.log(
      `Gateway health: ${isHealthy ? '‚úÖ Healthy' : '‚ùå Unhealthy'}\n`
    );

    if (!isHealthy) {
      console.log(
        'Please ensure the Inference Gateway is running with Docker Compose.'
      );
      process.exit(1);
    }

    // List available MCP tools
    console.log('üìã Listing available MCP tools...');
    const tools = await client.listTools();
    console.log(`Found ${tools.data.length} MCP tools:\n`);

    const fileTools = tools.data.filter((tool) =>
      ['read_file', 'write_file', 'list_directory'].includes(tool.name)
    );

    if (fileTools.length === 0) {
      console.log('‚ö†Ô∏è  No filesystem MCP tools available.');
      return;
    }

    console.log('üìÅ Available filesystem tools:');
    fileTools.forEach((tool, index) => {
      console.log(`${index + 1}. ${tool.name} - ${tool.description}`);
    });
    console.log('');

    // Track MCP tool calls for demonstration
    const toolCallTracker = {
      totalCalls: 0,
      toolsUsed: new Set<string>(),
      filesAccessed: new Set<string>(),
    };

    // Example: Analyze highest revenue from sales data
    console.log('=== Highest Revenue Analysis with MCP Tool Tracking ===\n');

    await client.streamChatCompletion(
      {
        model,
        messages: [
          {
            role: MessageRole.system,
            content: `You are a data analyst with filesystem access. You have access to tools that can read files from /tmp directory and write files to /tmp directory. When analyzing data, be thorough and provide specific insights.`,
          },
          {
            role: MessageRole.user,
            content:
              'Please read the sample_sales_data.csv file from the /tmp directory, analyze it to find the highest revenue transactions, and create a detailed summary report. Save the summary to /tmp/revenue_analysis.txt.',
          },
        ],
        max_tokens: 1500,
      },
      {
        onOpen: () => {
          console.log('üöÄ Starting revenue analysis...');
          console.log('üìä MCP Tool usage will be tracked below:\n');
        },
        onContent: (content) => process.stdout.write(content),
        onMCPTool: (toolCall) => {
          toolCallTracker.totalCalls++;
          toolCallTracker.toolsUsed.add(toolCall.function.name);

          console.log(
            `\nüîß [TOOL CALL #${toolCallTracker.totalCalls}] ${toolCall.function.name}`
          );

          const args = JSON.parse(toolCall.function.arguments);

          switch (toolCall.function.name) {
            case 'read_file':
              console.log(`   üìÑ Reading file: ${args.path}`);
              toolCallTracker.filesAccessed.add(args.path);
              break;
            case 'write_file':
              console.log(`   üíæ Writing file: ${args.path}`);
              console.log(
                `   üìù Content length: ${
                  args.content ? args.content.length : 0
                } characters`
              );
              toolCallTracker.filesAccessed.add(args.path);
              break;
            case 'list_directory':
              console.log(`   üìÇ Listing directory: ${args.path}`);
              break;
            default:
              console.log(`   ‚öôÔ∏è  Arguments: ${JSON.stringify(args, null, 2)}`);
          }
          console.log(`   üÜî Tool ID: ${toolCall.id}`);
        },
        onFinish: () => {
          console.log('\n\n‚úÖ Revenue analysis completed!\n');

          // Display tool usage summary
          console.log('üìà MCP Tool Usage Summary:');
          console.log(`   Total tool calls: ${toolCallTracker.totalCalls}`);
          console.log(
            `   Tools used: ${Array.from(toolCallTracker.toolsUsed).join(', ')}`
          );
          console.log(
            `   Files accessed: ${Array.from(
              toolCallTracker.filesAccessed
            ).join(', ')}`
          );
          console.log('');
        },
        onError: (error) => console.error('‚ùå Error:', error),
      },
      provider
    );

    console.log('üéâ MCP Tool Usage Demo completed successfully!');
    console.log('\nüí° Key takeaways:');
    console.log(
      '- The onMCPTool callback provides detailed tracking of tool usage'
    );
    console.log(
      '- Track total tool calls, tool types used, and files accessed'
    );
    console.log(
      '- Each tool call includes function name, arguments, and unique ID'
    );
    console.log(
      '- Perfect for debugging, monitoring, and understanding AI tool usage patterns'
    );
    console.log(
      '- LLM can read CSV data and perform complex analysis with file operations\n'
    );
  } catch (error) {
    if (
      error instanceof Error &&
      error.message.includes('MCP tools endpoint is not exposed')
    ) {
      console.error(
        '‚ùå MCP tools are not exposed. Please ensure the Inference Gateway is started with MCP_EXPOSE=true'
      );
      console.log('\nüí° To fix this, restart the gateway with:');
      console.log('   docker-compose up --build');
    } else {
      console.error('‚ùå Error:', error);
    }
  }
})();
